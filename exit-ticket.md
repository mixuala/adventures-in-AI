
# Exit Ticket
> what the audience should walk away with

AI > ML > Deep Learning: Why is it trending?!??
> Machine Learning is a field of study that gives computers the ability to learn without being explicitly programmed. --**Arthur Samuel**
> Computer programming is like the teacher who tells you exactly what to do to get an answer, Machine Learning is the teacher who tells you to figure it out for yourself

	Machine learning is: finding patterns in data and make predictions
	touchesing every corner of your life, (you can run but you can't hide)
	AI beats humans at...

(??? this could be better) why does it work? why now?

A peek behind the curtains:
	
	data data data
	life in n-dimensions (1e9)
	everything is a probability
	some examples
	
Lets get our hands dirty
	[understanding-neural-networks-with-tensorflow-playground](https://cloud.google.com/blog/products/gcp/understanding-neural-networks-with-tensorflow-playground)
	
** tensorflow playground **	
1. XOR, 
	- 6 neurons, try 3>3, 2>2>2,
	- 5: neurons: 3>2
	- 4: [2>2](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=xor&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=2,2&seed=0.83546&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)	
	
	(tensorflow playground)
	data: everything is a number
		supervised vs unsupervised learning
	perceptrons are the atoms of AI
	activations???
	a race to the bottom: loss equations & gradient descent
	putting it all together
	
So what really happened?

	data * (model + weights) = activations
	
???: whats hiding in those hidden layers?
	
	(visualizations)?
	or handle in "what did it really learn?"model + learned weights

different models for different tasks
	
	data, vision, text, sound, games,
	feed-forward, CNN, time-based, RL, GANs

out of the labs: train-test-deploy-repeat

	competitions
	pretrained models
	transfer learning
	more examples
	
what did it really learn?
	
	not sure
	interpretability: attribution, disentanglement
	edge cases

where do we go from here?	


what could possibly go wrong?
	
	where did you get that?/where does data come from	
ethics and AI 
	
	where did you get that data?
	was it biased?
	what decisions are (in)appropriate?
	what's the right decision? 
		fairness, accountability, transparency, 
	

Useful hashtags
		
		
#probability
		#adversarialAttacks

What did we leave out?
	
	- feature visualizations
		- activations
	- word2vec
	- benchmark datasets/competitions
		- imagenet
	- different models learn different things	
	



> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTAxNjU0MzkwNCwtMTcwODAyMDcyMiwtMT
IyMzc0MTU5NCwxMjM3NDc1NjYzLC01MjQ2NzU0NDUsMTc3NjI3
MjczMywzMjEwMzYwNzYsMTg2Njg3NzAxNSwtMjAwMTk3Nzc4NC
wtNzg3NzMzMTc4LC05MDU5MTc0MiwxODc3MDg3NzM1XX0=
-->